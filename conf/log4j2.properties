status = warn
name = SparkLog4j2

# Logger raiz do Spark
rootLogger.level = WARN
rootLogger.appenderRefs = console
rootLogger.appenderRef.console.ref = Console

# Console appender
appender.console.type = Console
appender.console.name = Console
appender.console.target = SYSTEM_OUT
appender.console.layout.type = PatternLayout
appender.console.layout.pattern = %d %-5p %c{1}: %m%n

# ↓↓↓ Aqui é a parte importante ↓↓↓

# Abaixa o nível de log especificamente do pacote Kafka do Spark
logger.kafka10.name = org.apache.spark.sql.kafka010
logger.kafka10.level = ERROR
logger.kafka10.additivity = false
logger.kafka10.appenderRefs = console
logger.kafka10.appenderRef.console.ref = Console

# E garante que o próprio KafkaDataConsumer obedeça isso
logger.kafkaDataConsumer.name = org.apache.spark.sql.kafka010.KafkaDataConsumer
logger.kafkaDataConsumer.level = ERROR
logger.kafkaDataConsumer.additivity = false
logger.kafkaDataConsumer.appenderRefs = console
logger.kafkaDataConsumer.appenderRef.console.ref = Console
